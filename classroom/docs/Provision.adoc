= DO500 Lab Environment Provisioning Guide
This guide provides all the necessary information for provisioning the classroom
environment for DO500 in AWS.

== Dependencies
The DO500 lab environment provisioning depends upon the following projects:

- casl-ansible
+
This Red Hat Communities of Practice project provides the main playbooks for
building the OpenShift cluster. It depends on the following projects:
+
** infra-ansible
+
These playbooks create add-on infrastructure for the cluster.
+
** openshift-ansible
+
These playbooks install the OpenShift cluster.
+
** openshift-applier
+
These playbooks apply resources to the OpenShift cluster after it is built.
+


== Prerequisites
1. AWS account with an IAM account enabled. You need the access and secret keys
for the account.
2. Access to the Employee SKU with redhat.com credentials.
3. A registry.redhat.io service account.
4. A hosted zone must be established in the AWS account. These instructions
currently assume `nextcle.com`
5. The Red Hat "Gold Images" need to be added to the AWS account. see https://access.redhat.com/articles/2962171.
6. A private key file for access to the instances. You may create and upload one
to your AWS account or use the glsdemo2.pem key. Contact Jim Rigsbee for the key file.

== Provisioning Steps
1. Set the following environment variables:
+
  RHSM_USER=<subscription-manager username>
  RHSM_PASSWD=<subscription-manager password>
  RHSM_POOL=<subscription pool for Employee SKU>
  REG_USERNAME=<registry.redhat.io service account username>
  REG_TOKEN=<registry.redhat.io service account token>
  AWS_ACCESS_KEY_ID=<AWS access key>
  AWS_SECRET_ACCESS_KEY=<AWS secret access key>
+
2. Pull in playbook dependencies using Ansible Galaxy:
+
  cd classroom
  ansible-galaxy install -r do500-requirements.yml -p galaxy
+
3. Follow the instructions at casl-ansible/docs/PROVISIONING_AWS.adoc using the
following notes:
+
* Example *provision.sh* and *deprovision.sh* scripts are given to help you with
the Docker run commands.  Adjust as needed.
* Create an inventory in casl-ansible/inventory by copying sample.aws.example.com folder.
* Completed *ec2.ini*, *all.yml*, and *OSEv3.yml* files are provided in *inventory_ocp/*.
Adjust as needed. All the private variables are provided through environment variables
so that we can easily reuse these scripts and check them in and not reveal any secrets.
Copy these files to the folder you created for the inventory in casl-ansible.
+
4. Using the AWS console, provision a t2.medium server with a DNS name of idm.<env_id>.nextcle.com.
Use the Gold Red Hat 7.5 AMI. Adjust the inventory files to match the host name.
Add Route53 records as follows:
* public zone: associate idm.labs.nextcle.com with its public DNS name
* private zone: associate idm.labs.nextcle.com with its private IP address (not name)
* Add a reverse DNS private zone, e.g. 1.20.10.in-addr.arpa for the VPC subnet. Add an entry for xxx.1.20.10.in-addr.arpa PTR pointing to idm.labs.nextcle.com.
5. Run the IDm provisioning playbook:
+
  ansible-playbook -i inventory_idm/ galaxy/casl-ansible/galaxy/infra-ansible/playbooks/provision-idm/idm.yml
+
Note: I had to comment out the import_playbook: dns.yml in idm.yml playbook so that it
does not try to create DNS records.
6. Add stanza to /etc/origin/master/master-config.yaml for identityProvider - see master-config.yaml.ldap for specific settings.
7. Add user accounts via https://idm.labs.nextcle.com. Reset passwords on each account.
8. Restart the master api and controllers. On master, /usr/local/bin/master-restart api and /usr/local/bin/master-restart controllers. You should now be able to login with LDAP credentials from IdM. 

=== TO DO List
2. Install Gitlab on cluster and tie to IDm
3. Provision user accounts on IDm
4. Reconcile this approach to building classroom with GPTE agnostic_deployer
